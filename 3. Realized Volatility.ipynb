{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53942600-b12e-4c54-879a-c6335ba6aac0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951bc39d-3b08-4af9-a4bd-41267aac78e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique permnos PRisk (cleaned): 5096\n",
      "vol_raw loaded from CSV\n",
      "Unique permnos PRisk (cleaned): 21651\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# Uploading Firmquarter\n",
    "# ---------------------------------\n",
    "\n",
    "# Load the CSV version you just uploaded\n",
    "prisk_df = pd.read_csv(\"firmquarter_permno.csv\")\n",
    "\n",
    "# Remove NaNs and convert to string\n",
    "prisk_df = prisk_df.dropna(subset=['permno'])\n",
    "prisk_df['permno'] = prisk_df['permno'].astype(str).str.strip()\n",
    "\n",
    "# Count unique permnos\n",
    "unique_permnos_PRisk = prisk_df['permno'].nunique()\n",
    "print(f\"Unique permnos PRisk (cleaned): {unique_permnos_PRisk}\")\n",
    "# Unique permnos PRisk (cleaned): 5096\n",
    "\n",
    "# ---------------------------------\n",
    "# Lading Volatility Document\n",
    "# ---------------------------------\n",
    "\n",
    "vol_raw = pd.read_csv(\"vol_raw.csv\", parse_dates=['date'])\n",
    "print(\"vol_raw loaded from CSV\")\n",
    "unique_permnos_vol = vol_raw['PERMNO'].nunique()\n",
    "print(f\"Unique permnos PRisk (cleaned): {unique_permnos_vol}\")\n",
    "\n",
    "# vol_raw loaded from CSV\n",
    "# Unique permnos PRisk (cleaned): 21651"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67287d9d-7f74-47be-9345-c40bf4955d46",
   "metadata": {},
   "source": [
    "##### Working only with Firmquarter PERMNOS data extracted from vol_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c50668-96ca-4701-ba69-facfe13877d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need volatility for 5096 permnos\n",
      "Filtered vol_raw shape: (14939431, 4)\n",
      "Saved: vol_raw_needed.csv\n",
      "Unique permnos: 5096\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# Working only with Firmquarter PERMNOS data extracted from vol_raw\n",
    "# This reduces the computational load to 1/4 (only 5k out of 20k)\n",
    "# ---------------------------------\n",
    "\n",
    "# Uploading PRisk\n",
    "prisk_df['permno'] = prisk_df['permno'].astype(float).astype(int).astype(str)\n",
    "needed_permnos = set(prisk_df['permno'].unique())\n",
    "print(f\"Need volatility for {len(needed_permnos)} permnos\")\n",
    "\n",
    "\n",
    "# Working with Vol\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(\"vol_raw.csv\", parse_dates=['date'], chunksize=500_000):\n",
    "    chunk['PERMNO'] = chunk['PERMNO'].astype(str)\n",
    "    filtered = chunk[chunk['PERMNO'].isin(needed_permnos)].copy()\n",
    "    chunks.append(filtered)\n",
    "\n",
    "vol_raw_filtered = pd.concat(chunks, ignore_index=True)\n",
    "print(f\"Filtered vol_raw shape: {vol_raw_filtered.shape}\")\n",
    "\n",
    "# Saving vol_raw_filtered to .csv\n",
    "vol_raw_filtered.to_csv(\"vol_raw_needed.csv\", index=False)\n",
    "print(\"Saved: vol_raw_needed.csv\")   \n",
    "\n",
    "# ---------------------------------\n",
    "# Verifying that they are the same 5,096 after filtering vol_raw_needed\n",
    "# ---------------------------------\n",
    "\n",
    "df = pd.read_csv(\"vol_raw_needed.csv\")\n",
    "df['PERMNO'] = df['PERMNO'].astype(str)\n",
    "unique_permnos = df['PERMNO'].unique()\n",
    "print(f\"Unique permnos: {len(unique_permnos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c058509-4bf7-4425-81be-6a0ec30c1847",
   "metadata": {},
   "source": [
    "##### Creating Realized Volatility as variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d0f131-0585-4bee-836a-87f2fd8a5197",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as 'volatility_hassan_style.csv'\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Upload file with daily returns from CRSP\n",
    "# -------------------------------\n",
    "vol_raw = pd.read_csv(\"vol_raw_needed.csv\", parse_dates=['date'])\n",
    "\n",
    "# -------------------------------\n",
    "# Normalize, clean and Q Column\n",
    "# -------------------------------\n",
    "vol_raw['PERMNO'] = vol_raw['PERMNO'].astype(str)\n",
    "vol_raw['RET'] = pd.to_numeric(vol_raw['RET'], errors='coerce') * 100  # Convertir a porcentaje\n",
    "vol_raw = vol_raw.dropna(subset=['RET'])\n",
    "vol_raw['quarter'] = vol_raw['date'].dt.to_period('Q').astype(str).str.upper()\n",
    "\n",
    "# -------------------------------\n",
    "# Calculate number of observations and standard deviation per PERMNO–quarter\n",
    "# -------------------------------\n",
    "agg = vol_raw.groupby(['PERMNO', 'quarter'])['RET'].agg(\n",
    "    n_obs='count',\n",
    "    volatility_raw='std'\n",
    ").reset_index()\n",
    "\n",
    "agg = agg[agg['n_obs'] >= 60].copy() # Filter by at least 60 days obs\n",
    "\n",
    "p01 = agg['volatility_raw'].quantile(0.01)\n",
    "p99 = agg['volatility_raw'].quantile(0.99)\n",
    "agg['volatility_winz'] = agg['volatility_raw'].clip(lower=p01, upper=p99) # Winsorization\n",
    "\n",
    "mean_ = agg['volatility_winz'].mean()\n",
    "std_ = agg['volatility_winz'].std()\n",
    "agg['volatility_std'] = (agg['volatility_winz'] - mean_) / std_ # Standardization\n",
    "\n",
    "volatility_df = agg[['PERMNO', 'quarter', 'volatility_std']]\n",
    "volatility_df.to_csv(\"volatility_hassan_style.csv\", index=False)\n",
    "print(\"File saved as 'volatility_hassan_style.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053cc6de-cf4a-4447-8a11-5816bb95c13d",
   "metadata": {},
   "source": [
    "##### Adding Assets to the panel_volatility_merged\n",
    "\n",
    "Reason for this: All specifications include a log of firm assets as a control. Page 17 of Hassan's technical file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215d4566-a752-4c68-a20b-cf8563324f37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as 'panel_volatility_with_assets.csv'\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Loading Cap Inv file\n",
    "# -------------------------------\n",
    "prisk_df = pd.read_csv(\"firmquarter_permno.csv\")\n",
    "volatility = pd.read_csv(\"volatility_hassan_style.csv\")  # Includes Volatility variable\n",
    "capinv = pd.read_csv(\"capinv.csv\")  # File with ATQ (Assets)\n",
    "\n",
    "prisk_df = prisk_df.dropna(subset=['permno'])\n",
    "prisk_df['PERMNO'] = prisk_df['permno'].astype(float).astype(int).astype(str)\n",
    "prisk_df['quarter'] = prisk_df['quarter'].astype(str).str.strip().str.upper()\n",
    "\n",
    "volatility['PERMNO'] = volatility['PERMNO'].astype(str)\n",
    "volatility['quarter'] = volatility['quarter'].astype(str).str.strip().str.upper()\n",
    "\n",
    "panel = pd.merge( #Merging PRisk + Vol\n",
    "    prisk_df,\n",
    "    volatility[['PERMNO', 'quarter', 'volatility_std']],\n",
    "    on=['PERMNO', 'quarter'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Calculating Log(Assets)\n",
    "# -------------------------------\n",
    "capinv['datadate'] = pd.to_datetime(capinv['datadate'], errors='coerce')\n",
    "capinv = capinv.dropna(subset=['datadate', 'atq'])\n",
    "capinv = capinv[capinv['atq'] > 0].copy()\n",
    "\n",
    "capinv['quarter'] = capinv['datadate'].dt.to_period('Q').astype(str).str.strip().str.upper()\n",
    "capinv['log_assets'] = np.log(capinv['atq'])\n",
    "capinv['gvkey'] = capinv['gvkey'].astype(int).astype(str)\n",
    "\n",
    "capinv_subset = capinv[['gvkey', 'quarter', 'log_assets']]\n",
    "\n",
    "panel['gvkey'] = panel['gvkey'].astype(int).astype(str)\n",
    "panel['quarter'] = panel['quarter'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# -------------------------------\n",
    "# Adding Log(Assets) to panel\n",
    "# -------------------------------\n",
    "panel = pd.merge(panel, capinv_subset, on=['gvkey', 'quarter'], how='left')\n",
    "panel.to_csv(\"panel_volatility_with_assets.csv\", index=False)\n",
    "print(\"File saved as 'panel_volatility_with_assets.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b559d8-1416-491b-a3e3-485a51ad0e7d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERMNO–quarter matches en PRisk: 166,477\n",
      "PERMNO–quarter matches in Volatility: 235,124\n",
      "Observations PRisk + Volatility: 156,430\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "\n",
    "prisk_df = pd.read_csv(\"firmquarter_permno.csv\")\n",
    "volatility = pd.read_csv(\"volatility_hassan_style.csv\")\n",
    "\n",
    "prisk_df = prisk_df.dropna(subset=['permno'])\n",
    "prisk_df['PERMNO'] = prisk_df['permno'].astype(float).astype(int).astype(str)\n",
    "prisk_df['quarter'] = prisk_df['quarter'].astype(str).str.upper().str.strip()\n",
    "\n",
    "volatility['PERMNO'] = volatility['PERMNO'].astype(str)\n",
    "volatility['quarter'] = volatility['quarter'].astype(str).str.upper().str.strip()\n",
    "\n",
    "# -------------------------------\n",
    "# Diagnosis prior merging\n",
    "# -------------------------------\n",
    "n_prisk = prisk_df[['PERMNO', 'quarter']].drop_duplicates().shape[0]\n",
    "n_vol = volatility[['PERMNO', 'quarter']].drop_duplicates().shape[0]\n",
    "\n",
    "print(f\"PERMNO–quarter matches en PRisk: {n_prisk:,}\")\n",
    "print(f\"PERMNO–quarter matches in Volatility: {n_vol:,}\")\n",
    "\n",
    "# -------------------------------\n",
    "# For merged data\n",
    "# -------------------------------\n",
    "merged = pd.merge(prisk_df, \n",
    "                  volatility[['PERMNO', 'quarter', 'volatility_std']], \n",
    "                  on=['PERMNO', 'quarter'], how='left')\n",
    "\n",
    "n_merged = merged[['PERMNO', 'quarter', 'volatility_std']].dropna().shape[0]\n",
    "print(f\"Observations PRisk + Volatility: {n_merged:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
