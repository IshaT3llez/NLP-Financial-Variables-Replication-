{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072f9b19-f3b9-4d9d-8c1c-8e24efe83565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062676de-6338-4acf-b6da-029f5f8eec25",
   "metadata": {},
   "source": [
    "#### Adding SECID to firmquarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafa1394-70a6-4f14-9c78-a54833c7fcd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1284085019.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  secid_df['effect_date'] = pd.to_datetime(secid_df['effect_date'], errors='coerce')\n",
      "/tmp/ipykernel_85247/1284085019.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  firmquarter['date_earningscall'] = pd.to_datetime(firmquarter['date_earningscall'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Adding SECID to firmquarter\n",
    "\n",
    "firmquarter = pd.read_csv(\"firmquarter.csv\")\n",
    "secid_df = pd.read_csv(\"secid.csv\")\n",
    "\n",
    "# Same CUSIP for both files\n",
    "firmquarter['cusip8'] = firmquarter['cusip'].astype(str).str.strip().str[:8]\n",
    "secid_df['cusip8'] = secid_df['cusip'].astype(str).str.strip().str[:8]\n",
    "\n",
    "# Parsing dates\n",
    "secid_df['effect_date'] = pd.to_datetime(secid_df['effect_date'], errors='coerce')\n",
    "firmquarter['date_earningscall'] = pd.to_datetime(firmquarter['date_earningscall'], errors='coerce')\n",
    "secid_clean = secid_df[['secid', 'cusip8', 'effect_date']].dropna()\n",
    "merged = firmquarter.merge(secid_clean, on='cusip8', how='left') #Merge many-to-many by cusip8\n",
    "\n",
    "# Filtering only records with effect_date <= date_earningscall\n",
    "merged = merged[merged['effect_date'] <= merged['date_earningscall']]\n",
    "merged = merged.sort_values(['gvkey', 'date_earningscall', 'effect_date'])\n",
    "merged = merged.drop_duplicates(subset=['gvkey', 'date_earningscall'], keep='last') # last valid earning call\n",
    "firmquarter_with_secid = merged.copy()\n",
    "\n",
    "\n",
    "firmquarter_with_secid.to_csv(\"firmquarter_with_secid.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b7249a-cb82-4da2-9e3b-61d32c8f3934",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total secid: 6533\n",
      "['189845\\n', '102510\\n', '109024\\n', '214847\\n', '5007\\n']\n"
     ]
    }
   ],
   "source": [
    "# Converting to .txt (to download from Compustat)\n",
    "\n",
    "prisk_secid = pd.read_csv(\"firmquarter_with_secid.csv\")\n",
    "\n",
    "# Unique SECID, converted to a string no decimals\n",
    "secid_list = (\n",
    "    prisk_secid['secid']\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .astype(str)\n",
    "    .str.replace(r'\\.0$', '', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# to .txt\n",
    "secid_list.to_csv(\"secid_hassan.txt\", index=False, header=False)\n",
    "with open(\"secid_hassan.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f\"Total secid: {len(lines)}\")\n",
    "print(lines[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b191391b-df49-40ce-a9ff-f91618627e43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved with 185616 rows and 50 columns\n"
     ]
    }
   ],
   "source": [
    "# Joining firmquarter secid 2002-2016 with 2017-2025\n",
    "\n",
    "firmquarter_old = pd.read_csv(\"firmquarter_with_secid.csv\")\n",
    "scores_new = pd.read_csv(\"scores_2017-25quarter.csv\")\n",
    "\n",
    "# Keys consistency\n",
    "for col in ['gvkey', 'secid']:\n",
    "    firmquarter_old[col] = pd.to_numeric(firmquarter_old[col], errors='coerce')\n",
    "    scores_new[col] = pd.to_numeric(scores_new[col], errors='coerce')\n",
    "\n",
    "firmquarter_old['quarter'] = firmquarter_old['quarter'].astype(str).str.upper()\n",
    "scores_new['quarter'] = scores_new['quarter'].astype(str).str.upper()\n",
    "firmquarter_full = pd.concat([firmquarter_old, scores_new], ignore_index=True)\n",
    "\n",
    "firmquarter_full.to_csv(\"firmquarter_with_secid_full.csv\", index=False)\n",
    "print(f\"File saved with {len(firmquarter_full)} rows and {len(firmquarter_full.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766bff6-1ebd-4436-999a-26d89530a46d",
   "metadata": {},
   "source": [
    "#### Implied Volatility Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b0ac584-5bed-4c9f-97aa-8cc2748106cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/3527273790.py:3: DtypeWarning: Columns (41,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prisk_secid = pd.read_csv(\"firmquarter_with_secid_full.csv\")\n",
      "/tmp/ipykernel_85247/3527273790.py:4: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  impvol1 = pd.read_csv(\"01-01-02 to 01-01-17.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Merging Firmquarter_with_SECID with existing SECIDs in the Impvol file\n",
    "\n",
    "prisk_secid = pd.read_csv(\"firmquarter_with_secid_full.csv\")\n",
    "impvol1 = pd.read_csv(\"01-01-02 to 01-01-17.csv\")\n",
    "impvol2 = pd.read_csv(\"01-01-17 to 31-08-22.csv\")\n",
    "impvol3 = pd.read_csv(\"31-08-22 to 31-08-23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41c9e75-fa4d-4365-a0ab-6c8e273a7b84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1336657472.py:3: DtypeWarning: Columns (41,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prisk_secid = pd.read_csv(\"firmquarter_with_secid_full.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01-01-02 to 01-01-17.csv] Chunk 1: 170628 saved rows (Total: 170628)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 2: 179246 saved rows (Total: 349874)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 3: 154450 saved rows (Total: 504324)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 4: 121446 saved rows (Total: 625770)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 5: 387458 saved rows (Total: 1013228)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 6: 433032 saved rows (Total: 1446260)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 7: 367138 saved rows (Total: 1813398)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 8: 403010 saved rows (Total: 2216408)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 9: 374774 saved rows (Total: 2591182)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 10: 374826 saved rows (Total: 2966008)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 11: 436784 saved rows (Total: 3402792)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 12: 367332 saved rows (Total: 3770124)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 13: 412162 saved rows (Total: 4182286)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 14: 370734 saved rows (Total: 4553020)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1336657472.py:13: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(pd.read_csv(f, chunksize=chunksize)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01-01-02 to 01-01-17.csv] Chunk 15: 260384 saved rows (Total: 4813404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1336657472.py:13: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(pd.read_csv(f, chunksize=chunksize)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01-01-02 to 01-01-17.csv] Chunk 16: 281700 saved rows (Total: 5095104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1336657472.py:13: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(pd.read_csv(f, chunksize=chunksize)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01-01-02 to 01-01-17.csv] Chunk 17: 423868 saved rows (Total: 5518972)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 18: 426178 saved rows (Total: 5945150)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 19: 396856 saved rows (Total: 6342006)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 20: 363318 saved rows (Total: 6705324)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 21: 404330 saved rows (Total: 7109654)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 22: 368514 saved rows (Total: 7478168)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 23: 415098 saved rows (Total: 7893266)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 24: 396326 saved rows (Total: 8289592)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 25: 355852 saved rows (Total: 8645444)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 26: 389240 saved rows (Total: 9034684)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 27: 401664 saved rows (Total: 9436348)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 28: 367560 saved rows (Total: 9803908)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 29: 400972 saved rows (Total: 10204880)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 30: 381846 saved rows (Total: 10586726)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 31: 296128 saved rows (Total: 10882854)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 32: 127984 saved rows (Total: 11010838)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 33: 288392 saved rows (Total: 11299230)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 34: 265556 saved rows (Total: 11564786)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 35: 276760 saved rows (Total: 11841546)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 36: 290818 saved rows (Total: 12132364)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 37: 336974 saved rows (Total: 12469338)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 38: 283004 saved rows (Total: 12752342)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 39: 269786 saved rows (Total: 13022128)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 40: 206834 saved rows (Total: 13228962)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 41: 229646 saved rows (Total: 13458608)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 42: 255568 saved rows (Total: 13714176)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 43: 300820 saved rows (Total: 14014996)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 44: 202582 saved rows (Total: 14217578)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 45: 236508 saved rows (Total: 14454086)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 46: 279230 saved rows (Total: 14733316)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 47: 317204 saved rows (Total: 15050520)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 48: 347718 saved rows (Total: 15398238)\n",
      "[01-01-02 to 01-01-17.csv] Chunk 49: 263326 saved rows (Total: 15661564)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 1: 196702 saved rows (Total: 15858266)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 2: 360404 saved rows (Total: 16218670)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 3: 412314 saved rows (Total: 16630984)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 4: 410752 saved rows (Total: 17041736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1336657472.py:13: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(pd.read_csv(f, chunksize=chunksize)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01-01-17 to 31-08-22.csv] Chunk 5: 306458 saved rows (Total: 17348194)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 6: 438194 saved rows (Total: 17786388)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 7: 392800 saved rows (Total: 18179188)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 8: 410990 saved rows (Total: 18590178)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 9: 405960 saved rows (Total: 18996138)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 10: 334182 saved rows (Total: 19330320)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 11: 274758 saved rows (Total: 19605078)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 12: 300714 saved rows (Total: 19905792)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 13: 217198 saved rows (Total: 20122990)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 14: 195684 saved rows (Total: 20318674)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 15: 254768 saved rows (Total: 20573442)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 16: 146478 saved rows (Total: 20719920)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 17: 267370 saved rows (Total: 20987290)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 18: 258464 saved rows (Total: 21245754)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 19: 325668 saved rows (Total: 21571422)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 20: 342304 saved rows (Total: 21913726)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 21: 340296 saved rows (Total: 22254022)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 22: 300152 saved rows (Total: 22554174)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 23: 322330 saved rows (Total: 22876504)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 24: 308252 saved rows (Total: 23184756)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 25: 281170 saved rows (Total: 23465926)\n",
      "[01-01-17 to 31-08-22.csv] Chunk 26: 199216 saved rows (Total: 23665142)\n",
      "[31-08-22 to 31-08-23.csv] Chunk 1: 346102 saved rows (Total: 24011244)\n",
      "[31-08-22 to 31-08-23.csv] Chunk 2: 336792 saved rows (Total: 24348036)\n",
      "[31-08-22 to 31-08-23.csv] Chunk 3: 169926 saved rows (Total: 24517962)\n",
      "[31-08-22 to 31-08-23.csv] Chunk 4: 260132 saved rows (Total: 24778094)\n",
      "[31-08-22 to 31-08-23.csv] Chunk 5: 235814 saved rows (Total: 25013908)\n",
      "[31-08-22 to 31-08-23.csv] Chunk 6: 144948 saved rows (Total: 25158856)\n",
      "Final file saved: impvol_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge and SECID Filtering\n",
    "\n",
    "prisk_secid = pd.read_csv(\"firmquarter_with_secid_full.csv\")\n",
    "secids_validos = set(prisk_secid['secid'].dropna().unique())\n",
    "\n",
    "# -------------------------------\n",
    "# Merge and filtering\n",
    "# -------------------------------\n",
    "def merge_y_filtrar_impvol(files, output_file, secids_validos, chunksize=500_000):\n",
    "    total_guardadas = 0\n",
    "    \n",
    "    for f in files:\n",
    "        for i, chunk in enumerate(pd.read_csv(f, chunksize=chunksize)):\n",
    "            filtrado = chunk[chunk['secid'].isin(secids_validos)]\n",
    "            \n",
    "            mode = 'a' if total_guardadas > 0 else 'w'\n",
    "            header = total_guardadas == 0\n",
    "            \n",
    "            filtrado.to_csv(output_file, mode=mode, header=header, index=False)\n",
    "            total_guardadas += len(filtrado)\n",
    "            \n",
    "            print(f\"[{f}] Chunk {i+1}: {len(filtrado)} saved rows (Total: {total_guardadas})\")\n",
    "    \n",
    "    print(f\"Final file saved: {output_file}\")\n",
    "\n",
    "# Execute\n",
    "merge_y_filtrar_impvol(\n",
    "    [\"01-01-02 to 01-01-17.csv\", \"01-01-17 to 31-08-22.csv\", \"31-08-22 to 31-08-23.csv\"],\n",
    "    \"impvol_filtered.csv\",\n",
    "    secids_validos\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e6eb8c-2ef8-4ba1-b1f6-f0e97f303389",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/3544383503.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"impvol_filtered.csv\", parse_dates=['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year    n_obs\n",
      "0   2002   674782\n",
      "1   2003   658570\n",
      "2   2004   717404\n",
      "3   2005   800472\n",
      "4   2006   867528\n",
      "5   2007   960714\n",
      "6   2008  1026904\n",
      "7   2009  1037392\n",
      "8   2010  1073346\n",
      "9   2011  1162414\n",
      "10  2012  1209564\n",
      "11  2013  1283344\n",
      "12  2014  1359702\n",
      "13  2015  1400464\n",
      "14  2016  1428964\n",
      "15  2017  1386390\n",
      "16  2018  1385138\n",
      "17  2019  1368820\n",
      "18  2020  1361470\n",
      "19  2021  1477424\n",
      "20  2022  1538248\n",
      "21  2023   979802\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"impvol_filtered.csv\", parse_dates=['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "obs_por_ano = df.groupby('year').size().reset_index(name='n_obs')\n",
    "obs_por_ano = obs_por_ano.sort_values('year')\n",
    "\n",
    "print(obs_por_ano)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6754b-879d-4aa0-b63f-f7783691833f",
   "metadata": {},
   "source": [
    "#### Implied Volatility Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91aa3acd-bd6a-4c3c-999f-68dee42b7cf2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: 4048 rows\n",
      "Chunk 2: 4047 rows\n",
      "Chunk 3: 4045 rows\n",
      "Chunk 4: 4020 rows\n",
      "Chunk 5: 4042 rows\n",
      "Chunk 6: 4027 rows\n",
      "Chunk 7: 4029 rows\n",
      "Chunk 8: 4034 rows\n",
      "Chunk 9: 4030 rows\n",
      "Chunk 10: 4023 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/2621002922.py:7: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(pd.read_csv(input_file, chunksize=chunksize, parse_dates=['date'])):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 11: 4038 rows\n",
      "Chunk 12: 4029 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/2621002922.py:7: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(pd.read_csv(input_file, chunksize=chunksize, parse_dates=['date'])):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 13: 4053 rows\n",
      "Chunk 14: 4034 rows\n",
      "Chunk 15: 4026 rows\n",
      "Chunk 16: 4039 rows\n",
      "Chunk 17: 4027 rows\n",
      "Chunk 18: 4024 rows\n",
      "Chunk 19: 4042 rows\n",
      "Chunk 20: 4046 rows\n",
      "Chunk 21: 4041 rows\n",
      "Chunk 22: 4035 rows\n",
      "Chunk 23: 4065 rows\n",
      "Chunk 24: 4078 rows\n",
      "Chunk 25: 4107 rows\n",
      "Chunk 26: 4087 rows\n",
      "Chunk 27: 4089 rows\n",
      "Chunk 28: 4086 rows\n",
      "Chunk 29: 4100 rows\n",
      "Chunk 30: 4111 rows\n",
      "Chunk 31: 4167 rows\n",
      "Chunk 32: 4151 rows\n",
      "Chunk 33: 4056 rows\n",
      "Chunk 34: 4055 rows\n",
      "Chunk 35: 4059 rows\n",
      "Chunk 36: 4054 rows\n",
      "Chunk 37: 4054 rows\n",
      "Chunk 38: 4061 rows\n",
      "Chunk 39: 4061 rows\n",
      "Chunk 40: 4067 rows\n",
      "Chunk 41: 4080 rows\n",
      "Chunk 42: 4078 rows\n",
      "Chunk 43: 4090 rows\n",
      "Chunk 44: 4080 rows\n",
      "Chunk 45: 4096 rows\n",
      "Chunk 46: 4184 rows\n",
      "Chunk 47: 4322 rows\n",
      "Chunk 48: 4895 rows\n",
      "Chunk 49: 5001 rows\n",
      "Chunk 50: 5050 rows\n",
      "Chunk 51: 1589 rows\n",
      "File Saved: impvol_collapsed_raw.csv\n",
      "File saved as 'impvol_hassan_style.csv'\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Function for working with ImpVol in chunks\n",
    "# -------------------------------\n",
    "def colapsar_impvol_hassan(input_file, output_file, chunksize=500_000):\n",
    "    temp_results = []\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(input_file, chunksize=chunksize, parse_dates=['date'])):\n",
    "        chunk = chunk[chunk['days'] == 91].copy() # 90-day at-the-money options\n",
    "        chunk['quarter'] = chunk['date'].dt.to_period('Q').astype(str).str.upper()\n",
    "        agg = chunk.groupby(['secid', 'quarter'])['impl_volatility'].mean().reset_index() # Mean by Q\n",
    "        agg.rename(columns={'impl_volatility': 'impvol_mean'}, inplace=True)\n",
    "        \n",
    "        temp_results.append(agg)\n",
    "        print(f\"Chunk {i+1}: {len(agg)} rows\")\n",
    "    \n",
    "    # Concatenate\n",
    "    final_df = pd.concat(temp_results, ignore_index=True)\n",
    "    final_df = final_df.groupby(['secid', 'quarter'])['impvol_mean'].mean().reset_index() # Group duplicated\n",
    "    \n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"File Saved: {output_file}\")\n",
    "    return final_df\n",
    "\n",
    "# -------------------------------\n",
    "# Hassan variable specifications calculation\n",
    "# -------------------------------\n",
    "impvol_collapsed = colapsar_impvol_hassan(\"impvol_filtered.csv\", \"impvol_collapsed_raw.csv\")\n",
    "\n",
    "p01 = impvol_collapsed['impvol_mean'].quantile(0.01)\n",
    "p99 = impvol_collapsed['impvol_mean'].quantile(0.99)\n",
    "impvol_collapsed['impvol_winz'] = impvol_collapsed['impvol_mean'].clip(lower=p01, upper=p99) # Winsorization same as RV\n",
    "\n",
    "mean_ = impvol_collapsed['impvol_winz'].mean()\n",
    "std_ = impvol_collapsed['impvol_winz'].std()\n",
    "impvol_collapsed['impvol_std'] = (impvol_collapsed['impvol_winz'] - mean_) / std_ # Standardization\n",
    "\n",
    "\n",
    "impvol_collapsed[['secid', 'quarter', 'impvol_std']].to_csv(\"impvol_hassan_style.csv\", index=False)\n",
    "print(\"File saved as 'impvol_hassan_style.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ffdf1f-2ab9-4673-bb08-4365acf994aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85247/1540914549.py:3: DtypeWarning: Columns (41,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  firmquarter = pd.read_csv(\"firmquarter_with_secid_full.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final panel: 185617 filas\n",
      "Impvol Obs: 147291\n",
      "Log Assets Obs: 183620\n"
     ]
    }
   ],
   "source": [
    "# Joining Firmquarter with Secid (To then run regressions)\n",
    "\n",
    "firmquarter = pd.read_csv(\"firmquarter_with_secid_full.csv\")\n",
    "impvol = pd.read_csv(\"impvol_hassan_style.csv\")\n",
    "capinv = pd.read_csv(\"capinv.csv\")  # ATQ (Assets)\n",
    "\n",
    "firmquarter['secid'] = pd.to_numeric(firmquarter['secid'], errors='coerce') # Formating \n",
    "impvol['secid'] = pd.to_numeric(impvol['secid'], errors='coerce')\n",
    "\n",
    "firmquarter['quarter'] = firmquarter['quarter'].astype(str).str.strip().str.upper()\n",
    "impvol['quarter'] = impvol['quarter'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# -------------------------------\n",
    "# Log_assets calculation\n",
    "# -------------------------------\n",
    "capinv['datadate'] = pd.to_datetime(capinv['datadate'], errors='coerce')\n",
    "capinv = capinv.dropna(subset=['datadate', 'atq'])\n",
    "capinv = capinv[capinv['atq'] > 0].copy()\n",
    "\n",
    "capinv['quarter'] = capinv['datadate'].dt.to_period('Q').astype(str).str.strip().str.upper()\n",
    "capinv['log_assets'] = np.log(capinv['atq'])\n",
    "capinv['gvkey'] = pd.to_numeric(capinv['gvkey'], errors='coerce')\n",
    "\n",
    "capinv_subset = capinv[['gvkey', 'quarter', 'log_assets']].drop_duplicates()\n",
    "\n",
    "panel_final = firmquarter.merge( # Merging Firmquarter (PRisk) + Impvol\n",
    "    impvol[['secid', 'quarter', 'impvol_std']],\n",
    "    on=['secid', 'quarter'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "panel_final['gvkey'] = pd.to_numeric(panel_final['gvkey'], errors='coerce') # Merging with Log(Assets)\n",
    "panel_final = panel_final.merge(\n",
    "    capinv_subset,\n",
    "    on=['gvkey', 'quarter'],\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "# Save file\n",
    "panel_final.to_csv(\"panel_final_impvol_with_assets.csv\", index=False)\n",
    "print(f\"Final panel: {len(panel_final)}\")\n",
    "print(f\"Impvol Obs: {panel_final['impvol_std'].notna().sum()}\")\n",
    "print(f\"Log Assets Obs: {panel_final['log_assets'].notna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a040a-c7ef-41b2-a952-aa49402376b0",
   "metadata": {},
   "source": [
    "##### OLS + FE Regressions (Hassan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38dc8bc8-b31e-40d4-b9ce-f7d6f59a98e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87214/1367912347.py:3: DtypeWarning: Columns (41,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  panel = pd.read_csv(\"panel_final_impvol_with_assets.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Panel A (Table IV): impvol_std ~ PRisk_std (2002–2016)\n",
      "|           | (1)     | (2)      | (3)     | (4)      |\n",
      "|:----------|:--------|:---------|:--------|:---------|\n",
      "| PRisk_std | 0.016** | 0.030*** | 0.004   | 0.015*** |\n",
      "|           | (0.007) | (0.006)  | (0.007) | (0.006)  |\n",
      "| N         | 87562   | 87562    | 87562   | 87562    |\n",
      "| Adj. R²   | 0.001   | 0.200    | 0.172   | 0.412    |\n"
     ]
    }
   ],
   "source": [
    "# Uncomment Model 5 (Sometimes it gets stuck)\n",
    "\n",
    "panel = pd.read_csv(\"panel_final_impvol_with_assets.csv\")\n",
    "\n",
    "# Cleaning NAs\n",
    "panel.replace(['na', 'NA', 'NaN', 'nan', '', 'NONE', 'None'], np.nan, inplace=True)\n",
    "\n",
    "cols_to_numeric = ['PRisk', 'impvol_std', 'log_assets', 'SIC']\n",
    "for col in cols_to_numeric:\n",
    "    panel[col] = pd.to_numeric(panel[col], errors='coerce')\n",
    "\n",
    "# Filtering for 2002–2016\n",
    "panel['quarter'] = panel['quarter'].astype(str).str.strip().str.upper()\n",
    "panel['year'] = panel['quarter'].str[:4].astype(int)\n",
    "panel = panel[(panel['year'] >= 2002) & (panel['year'] <= 2016)].copy()\n",
    "\n",
    "#Variable creation for OLS Specification\n",
    "panel['sic2'] = panel['SIC'].floordiv(100)\n",
    "panel = panel.dropna(subset=['sic2'])\n",
    "panel['sic2'] = panel['sic2'].astype(int).astype(str)\n",
    "\n",
    "panel['gvkey'] = panel['gvkey'].astype(str)\n",
    "panel['PRisk_std'] = (panel['PRisk'] - panel['PRisk'].mean()) / panel['PRisk'].std()\n",
    "\n",
    "subset = panel.dropna(subset=[\n",
    "    'impvol_std', 'PRisk_std', 'log_assets', 'quarter', 'gvkey'\n",
    "]).copy()\n",
    "\n",
    "# -------------------------------\n",
    "# Regressions – Panel A\n",
    "# -------------------------------\n",
    "\n",
    "# Col 1: Solo PRisk\n",
    "model1 = smf.ols(\"impvol_std ~ PRisk_std\", data=subset).fit(\n",
    "    cov_type='cluster', cov_kwds={'groups': subset['gvkey']})\n",
    "\n",
    "# Col 2: + log_assets\n",
    "model2 = smf.ols(\"impvol_std ~ PRisk_std + log_assets\", data=subset).fit(\n",
    "    cov_type='cluster', cov_kwds={'groups': subset['gvkey']})\n",
    "\n",
    "# Col 3: + quarter FE\n",
    "model3 = smf.ols(\"impvol_std ~ PRisk_std + C(quarter)\", data=subset).fit(\n",
    "    cov_type='cluster', cov_kwds={'groups': subset['gvkey']})\n",
    "\n",
    "# Col 4: + quarter FE + sector FE\n",
    "model4 = smf.ols(\"impvol_std ~ PRisk_std + log_assets + C(quarter) + C(sic2)\", data=subset).fit(\n",
    "    cov_type='cluster', cov_kwds={'groups': subset['gvkey']})\n",
    "\n",
    "# Col 5: + quarter FE + firm FE\n",
    "#model5 = smf.ols(\"impvol_std ~ PRisk_std + log_assets + C(quarter) + C(gvkey)\", data=subset).fit(\n",
    "    #cov_type='cluster', cov_kwds={'groups': subset['gvkey']})\n",
    "\n",
    "# -------------------------------\n",
    "# Results table\n",
    "# -------------------------------\n",
    "models = [model1, model2, model3, model4] #model5]\n",
    "labels = ['(1)', '(2)', '(3)', '(4)'] #'(5)']\n",
    "\n",
    "def format_coef(model, var='PRisk_std'):\n",
    "    coef = model.params[var]\n",
    "    se = model.bse[var]\n",
    "    pval = model.pvalues[var]\n",
    "\n",
    "    stars = ''\n",
    "    if pval < 0.01:\n",
    "        stars = '***'\n",
    "    elif pval < 0.05:\n",
    "        stars = '**'\n",
    "    elif pval < 0.1:\n",
    "        stars = '*'\n",
    "\n",
    "    coef_str = f\"{coef:.3f}{stars}\"\n",
    "    se_str = f\"({se:.3f})\"\n",
    "    return coef_str, se_str\n",
    "\n",
    "table_data = {'PRisk_std': [], '': [], 'N': [], 'Adj. R²': []}\n",
    "\n",
    "for m in models:\n",
    "    coef, se = format_coef(m)\n",
    "    table_data['PRisk_std'].append(coef)\n",
    "    table_data[''].append(se)\n",
    "    table_data['N'].append(int(m.nobs))\n",
    "    table_data['Adj. R²'].append(f\"{m.rsquared_adj:.3f}\")\n",
    "\n",
    "table_df = pd.DataFrame(table_data, index=labels).T\n",
    "\n",
    "print(\"\\nPanel A (Table IV): impvol_std ~ PRisk_std (2002–2016)\")\n",
    "print(table_df.to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42088e-b4a7-47bf-96af-066f8c1baf75",
   "metadata": {},
   "source": [
    "##### Adding Lobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8119a47-b492-46d9-a847-a3056700b96d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firms with Lobby in final panel: 1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87214/1941310536.py:8: DtypeWarning: Columns (41,45,46,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  panel = pd.read_csv(\"panel_final_impvol_with_assets.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Lobbying\n",
    "lobby = pd.read_csv(\"Lobby_final_gvkeys_fuzzy.csv\")\n",
    "lobby = lobby[lobby[\"gvkey\"].notna()]\n",
    "lobby[\"gvkey\"] = lobby[\"gvkey\"].astype(str).str.strip()\n",
    "lobby[\"gvkey\"] = lobby[\"gvkey\"].astype(int).astype(str).str.zfill(6)\n",
    "\n",
    "# Panel\n",
    "panel = pd.read_csv(\"panel_final_impvol_with_assets.csv\")\n",
    "panel = panel[panel[\"gvkey\"].notna()]\n",
    "panel[\"gvkey\"] = panel[\"gvkey\"].astype(float).astype(int).astype(str).str.zfill(6)\n",
    "\n",
    "# Intersection\n",
    "firmas_comunes = set(lobby[\"gvkey\"]).intersection(set(panel[\"gvkey\"]))\n",
    "print(\"Firms with Lobby in final panel:\", len(firmas_comunes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df255dad-aa02-4f99-a534-4e86999db3ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  quarter\n",
      "184328  2023        3\n",
      "184331  2024        3\n",
      "184338  2022        2\n",
      "184359  2025        2\n",
      "184360  2024        2\n"
     ]
    }
   ],
   "source": [
    "# Final Merge\n",
    "\n",
    "panel = pd.read_csv(\"panel_final_impvol_with_assets.csv\", low_memory=False)\n",
    "panel[\"year\"] = panel[\"quarter\"].str.extract(r\"(\\d{4})\").astype(\"Int64\")\n",
    "panel[\"quarter_num\"] = panel[\"quarter\"].str.extract(r\"Q([1-4])\").astype(\"Int64\")\n",
    "panel = panel.drop(columns=[\"quarter\"])\n",
    "panel = panel.rename(columns={\"quarter_num\": \"quarter\"})\n",
    "\n",
    "# Checkin result\n",
    "print(panel[[\"year\", \"quarter\"]].dropna().drop_duplicates().tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711356db-ec16-4b6b-8577-6a3cd7cb5a7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs wiht lobbying: 29055\n",
      "Firms with lobbying: 1301\n"
     ]
    }
   ],
   "source": [
    "# Loading Lobbying file\n",
    "\n",
    "lobby = pd.read_csv(\"Lobby_final_gvkeys_fuzzy.csv\")\n",
    "\n",
    "# Cleaning Lobby panel \n",
    "\n",
    "lobby[\"gvkey\"] = pd.to_numeric(lobby[\"gvkey\"], errors=\"coerce\")\n",
    "lobby = lobby[lobby[\"gvkey\"].notna()]\n",
    "lobby[\"gvkey\"] = lobby[\"gvkey\"].astype(int).astype(str).str.zfill(6)\n",
    "\n",
    "lobby[\"year\"] = pd.to_numeric(lobby[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "lobby[\"quarter\"] = pd.to_numeric(lobby[\"quarter\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Cleaning main panel\n",
    "\n",
    "panel = pd.read_csv(\"panel_final_impvol_with_assets.csv\", low_memory=False)\n",
    "\n",
    "panel[\"year\"] = panel[\"quarter\"].str.extract(r\"(\\d{4})\").astype(\"Int64\")\n",
    "panel[\"quarter\"] = panel[\"quarter\"].str.extract(r\"Q([1-4])\").astype(\"Int64\")\n",
    "\n",
    "panel[\"gvkey\"] = pd.to_numeric(panel[\"gvkey\"], errors=\"coerce\")\n",
    "panel = panel[panel[\"gvkey\"].notna()]\n",
    "panel[\"gvkey\"] = panel[\"gvkey\"].astype(int).astype(str).str.zfill(6)\n",
    "\n",
    "panel_merged = panel.merge(lobby, on=[\"gvkey\", \"year\", \"quarter\"], how=\"left\") # Merge panel + lobby\n",
    "\n",
    "# Lobbying variables for Regressions\n",
    "panel_merged[\"lobby_usd\"] = pd.to_numeric(panel_merged[\"lobby_usd\"], errors=\"coerce\")\n",
    "panel_merged[\"log_lobby_usd\"] = np.log1p(panel_merged[\"lobby_usd\"])\n",
    "panel_merged[\"has_lobbying\"] = panel_merged[\"lobby_usd\"].notna().astype(int)\n",
    "\n",
    "# Results\n",
    "\n",
    "panel_merged.to_csv(\"panel_with_lobbying_impvol.csv\", index=False)\n",
    "print(\"Obs wiht lobbying:\", panel_merged[\"has_lobbying\"].sum())\n",
    "print(\"Firms with lobbying:\", panel_merged.loc[panel_merged[\"has_lobbying\"]==1, \"gvkey\"].nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
